{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import needest modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda is ready\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim \n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable \n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from VAE.model import VAE\n",
    "from VAE.data import Ego4d, DEVICE, BATCH_SIZE, transform1, transform2, ResumableRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/home/qwest/project/PycharmProjects/Reinforsment_Learning/VAE/weights/main/VAE_checkpoint_32_163.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform initializate sucsess\n",
      "train_dataset init\n",
      "train_sampler init\n",
      "train_loader init\n"
     ]
    }
   ],
   "source": [
    "print('transform initializate sucsess')\n",
    "train_dataset = Ego4d(img_dir='/home/qwest/data_for_ml/1_MARIO',\n",
    "                           transform1=transform1,\n",
    "                           transform2=transform2)\n",
    "print(\"train_dataset init\")\n",
    "sampler = ResumableRandomSampler(train_dataset)\n",
    "#sampler.set_state(checkpoint['sampler_state'])\n",
    "print(\"train_sampler init\")\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                           batch_size=32,\n",
    "                           shuffle=False,\n",
    "                           sampler=sampler,\n",
    "                           num_workers=6)\n",
    "print(\"train_loader init\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of trainloader:  6063\n"
     ]
    }
   ],
   "source": [
    "print(\"Len of trainloader: \",len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sampler.get_state(), \"test_samp.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup param's for VAE training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 25\n",
    "latent_dim = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create model & optimizer with parametrs ^^^ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(latent_dim, batch_size=32).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model.pt', weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/home/qwest/project/PycharmProjects/Reinforsment_Learning/VAE/weights/main/VAE_checkpoint_32_163.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create train func "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "        \"\"\"\n",
    "        train VAE model.\n",
    "\n",
    "        Args:\n",
    "        epoch (int): number of epoch.\n",
    "        \"\"\"\n",
    "\n",
    "        x = next(iter(train_loader))\n",
    "        model.train()\n",
    "        print(f'Epoch {epoch} start')\n",
    "        eval_loss = 0\n",
    "        # Loop through all batches in the training dataset\n",
    "        for i, data, in enumerate(tqdm(train_loader)):\n",
    "                data = data.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                recon_batch, mu, logvar = model(data)\n",
    "                loss = model.loss_function(recon_batch, data, mu, logvar)\n",
    "                eval_loss += loss\n",
    "                \n",
    "                loss.backward() # Compute the gradients with respect to the model parameters\n",
    "                \n",
    "                optimizer.step() # Update the model parameters using the optimizer\n",
    "\n",
    "        torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss':loss,\n",
    "                        'epoch':epoch,\n",
    "                        'full_model':model,\n",
    "                        'sampler_state':sampler.get_state(),\n",
    "                        },\n",
    "                        f'VAE/weights/main/VAE_checkpoint_{latent_dim}_{epoch}_MARIO.pt')\n",
    "        \n",
    "        print(f\"Avg loss: {loss:2f} \\n\")\n",
    "        model.eval()\n",
    "        recon_img, _, _ = model(x[:1].to(DEVICE))\n",
    "        img = recon_img.view(3, 64, 64).detach().cpu().numpy().transpose(1, 2, 0)\n",
    "        f = plt.imshow(img)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model with logging on mlflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 2247/6063 [09:57<17:00,  3.74it/s]"
     ]
    }
   ],
   "source": [
    "# Log model summary.|\n",
    "with open(\"model_summary.txt\", \"w\") as f:\n",
    "    f.write(str(summary(model)))\n",
    "\n",
    "for t in range(epoch, epochs+1):\n",
    "    train(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model, x.to(DEVICE), \"model.onnx\", input_names=['image'], output_names=['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('/home/qwest/project/PycharmProjects/Reinforsment_Learning/test_W/VAE_checkpoint_1283.pt')\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test on exist image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(train_loader))\n",
    "print(x.size())\n",
    "reconstructed, mu, _ = model(x.to(DEVICE))\n",
    "reconstructed = reconstructed.view(-1, 3, 64, 64).detach().cpu().numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "fig = plt.figure(figsize=(25, 16))\n",
    "for ii, img in enumerate(reconstructed):\n",
    "    ax = fig.add_subplot(4, 8, ii + 1, xticks=[], yticks=[])\n",
    "    plt.imshow((img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transition of image to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = model.encoder(x.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = Variable(torch.randn(32, latent_dim, 4, 4)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(samples[3].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z[0][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_dog_idx = 3\n",
    "second_dog_idx = 8\n",
    "\n",
    "dz = (mu[second_dog_idx] - mu[first_dog_idx]) / 31\n",
    "walk = Variable(torch.randn(32, latent_dim, 4, 4)).to(DEVICE)\n",
    "walk[0] = mu[first_dog_idx]\n",
    "\n",
    "for i in range(1, 32):\n",
    "    walk[i] = walk[i-1] + dz\n",
    "walk = model.decoder(walk).detach().cpu().numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "fig = plt.figure(figsize=(25, 16))\n",
    "for ii, img in enumerate(walk):\n",
    "    ax = fig.add_subplot(4, 8, ii + 1, xticks=[], yticks=[])\n",
    "    plt.imshow((img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate image from nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = Variable(torch.randn(32, latent_dim, 4, 4)).to(DEVICE)\n",
    "samples = model.decoder(samples).detach().cpu().numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "fig = plt.figure(figsize=(25, 16))\n",
    "for ii, img in enumerate(samples):\n",
    "    ax = fig.add_subplot(4, 8, ii + 1, xticks=[], yticks=[])\n",
    "    plt.imshow((img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed, _, _ = model(x[0][None, :, :, :].to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = reconstructed.view(-1, 3, 64, 64).detach().cpu().numpy().transpose(0, 2, 3, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Создаем исходный массив\n",
    "array = np.zeros((1, latent_dim, 4, 4))\n",
    "\n",
    "# Функция для изменения случайных элементов\n",
    "def update_array(change):\n",
    "  global array # Важно указать global, чтобы функция могла изменить глобальную переменную\n",
    "  indices = np.random.choice(np.arange(array.size), size=8, replace=False)\n",
    "  new_values = np.random.uniform(-5.0, 5.0, size=8)\n",
    "  array.reshape(-1)[indices] = new_values\n",
    "  samples = model.decoder(torch.tensor(array).float().to(DEVICE)).detach().cpu().numpy().transpose(0, 2, 3, 1)\n",
    "  plt.imshow(samples[0])\n",
    "  #print(\"Modified array:\\n\", array)\n",
    "\n",
    "\n",
    "# Создаем ползунок\n",
    "slider = widgets.IntSlider(\n",
    "  min=0,\n",
    "  max=50, # Максимальное значение - для демонстрации, можно изменить\n",
    "  step=1,\n",
    "  description='Update array:',\n",
    "  continuous_update=False, # Обновление только при отпускании ползунка\n",
    "  orientation='horizontal',\n",
    "  layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "# Связываем ползунок с функцией обновления\n",
    "slider.observe(update_array, names='value')\n",
    "\n",
    "\n",
    "# Выводим ползунок и начальный массив\n",
    "display(slider)\n",
    "#print(\"Initial array:\\n\", array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Создаем исходный массив # Замените на ваше значение latent_dim\n",
    "array = np.zeros((1, 32, 4, 4))\n",
    "\n",
    "# Инициализируем matplotlib для интерактивного режима\n",
    "plt.ion()\n",
    "fig, ax = plt.subplots()\n",
    "img = ax.imshow(np.zeros((64,64,3))) # Инициализируем изображение нулями с тремя каналами\n",
    "plt.show() # Важно показать график до начала обновления\n",
    "\n",
    "# Функция для изменения случайных элементов\n",
    "def update_array(change):\n",
    "  global array, img\n",
    "  indices = np.random.choice(np.arange(array.size), size=8, replace=False)\n",
    "  new_values = np.random.uniform(-5.0, 5.0, size=8)\n",
    "  array.reshape(-1)[indices] = new_values\n",
    "  samples = model.decoder(torch.tensor(array).float().to(DEVICE)).detach().cpu().numpy().transpose(0, 2, 3, 1)\n",
    "  img.set_data(samples[0]) # Обновляем данные изображения\n",
    "  fig.canvas.draw()     # Перерисовываем изображение\n",
    "   # Очищаем буфер событий (для гладкости)\n",
    "  print(1)\n",
    "\n",
    "\n",
    "# Создаем ползунок\n",
    "slider = widgets.IntSlider(\n",
    "  min=0,\n",
    "  max=50,\n",
    "  step=1,\n",
    "  description='Update array:',\n",
    "  continuous_update=False,\n",
    "  orientation='horizontal',\n",
    "  layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "# Связываем ползунок с функцией обновления\n",
    "slider.observe(update_array, names='value')\n",
    "\n",
    "# Выводим ползунок\n",
    "display(slider)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = torch.tensor(array).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = model.decoder(torch.tensor(array).float().to(DEVICE)).detach().cpu().numpy().transpose(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.ReLU()\n",
    "input = torch.randn(100, 1000, 100, 100)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[37][23][8][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinforsment-learning-cw9s_yh0-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
