{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda is ready\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from VAE.model import VAE\n",
    "from VAE.data import Ego4d, DEVICE, BATCH_SIZE, transform1, transform2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform initializate sucsess\n",
      "train_dataset init\n",
      "train_loader init\n"
     ]
    }
   ],
   "source": [
    "print('transform initializate sucsess')\n",
    "train_dataset = Ego4d(img_dir='/home/qwest/data_for_ml/ROBO/',\n",
    "                           transform1=transform1,\n",
    "                           transform2=transform2)\n",
    "print(\"train_dataset init\")\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                           batch_size=BATCH_SIZE,\n",
    "                           shuffle=True,\n",
    "                           num_workers=14)\n",
    "print(\"train_loader init\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.load(\"VAE/train_loadet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/938691871912139122', creation_time=1729683533514, experiment_id='938691871912139122', last_update_time=1729683533514, lifecycle_stage='active', name='/mlflow-pytorch-quickstart', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"/mlflow-pytorch-quickstart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "epochs = 50\n",
    "latent_dim = 32\n",
    "\n",
    "model = VAE(latent_dim, batch_size=BATCH_SIZE).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    #for epoch in range(1, epochs+1):\n",
    "    x = next(iter(train_loader))\n",
    "    model.train()\n",
    "    print(f'Epoch {epoch} start')\n",
    "    eval_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "            data = data.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss = model.loss_function(recon_batch, data, mu, logvar)\n",
    "            eval_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            \n",
    "    model.eval()\n",
    "    total_loss = eval_loss/BATCH_SIZE\n",
    "    mlflow.log_metric(\"total_loss\", f\"{total_loss:2f}\", step=epoch)\n",
    "    print(f\"Avg loss: {total_loss:2f} \\n\")\n",
    "#    recon_img, _, _ = model(x[:1].to(DEVICE))\n",
    "#    img = recon_img.view(3, 64, 64).detach().cpu().numpy().transpose(1, 2, 0)\n",
    "        \n",
    "        #torch.save(train_loader, f'train_loadet_{epochs}.pt')\n",
    "    #torch.save(model, f'VAE_{epoch}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(model(torch.tensor(input)[:1].to(DEVICE))[0][0].view(3, 64, 64).detach().cpu().numpy().transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signature = mlflow.models.infer_signature(\n",
    "#     input,\n",
    "#     model(torch.tensor(input)[:1].to(DEVICE))[0][0].view(3, 64, 64).detach().cpu().numpy().transpose(1, 2, 0),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluation(dataloader, model, loss_fn, epochs):\n",
    "#     num_batches = len(dataloader)\n",
    "#     model.eval()\n",
    "#     eval_loss = 0.0\n",
    "#     with torch.no_grad():\n",
    "#         for X in dataloader:\n",
    "#             Y = model(torch.tensor(X)[:1].to(DEVICE))[0][0].view(3, 64, 64).detach().cpu().numpy()\n",
    "#             eval_loss += loss_fn(torch.tensor(Y), torch.tensor(X[0])).item()\n",
    "#     eval_loss /= num_batches\n",
    "#     mlflow.log_metric(\"eval_loss\", f\"{eval_loss:2f}\", step=epochs)\n",
    "#     print(f\"Avg loss: {eval_loss:2f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 start\n",
      "Avg loss: 7.271623 \n",
      "\n",
      "Epoch 2 start\n",
      "Avg loss: 6.968933 \n",
      "\n",
      "Epoch 3 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/23 21:50:09 INFO mlflow.tracking._tracking_service.client: 🏃 View run amazing-fly-538 at: http://localhost:8080/#/experiments/938691871912139122/runs/f034ed70b99b4f8aa33c3d8028518459.\n",
      "2024/10/23 21:50:09 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:8080/#/experiments/938691871912139122.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[224], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_artifact(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_summary.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m#train(train_dataloader, model, loss_fn, metric_fn, optimizer, epoch=t)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m#evaluation(train_loader, model, loss_fn, epochs=t)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Save the trained model to MLflow.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mpytorch\u001b[38;5;241m.\u001b[39mlog_model(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, signature\u001b[38;5;241m=\u001b[39msignature)\n",
      "Cell \u001b[0;32mIn[221], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m eval_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m----> 8\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     11\u001b[0m         recon_batch, mu, logvar \u001b[38;5;241m=\u001b[39m model(data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    params = {\n",
    "        \"epochs\": epochs,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"batch_size\": 32,\n",
    "        #\"loss_function\": loss_fn.__class__.__name__,\n",
    "        \"metric_function\": \"BCE\",\n",
    "        \"optimizer\": \"Adam\",\n",
    "    }\n",
    "    # Log training parameters.\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log model summary.\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(model)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "    for t in range(1, epochs+1):\n",
    "        train(t)\n",
    "        #train(train_dataloader, model, loss_fn, metric_fn, optimizer, epoch=t)\n",
    "        #evaluation(train_loader, model, loss_fn, epochs=t)\n",
    "\n",
    "    # Save the trained model to MLflow.\n",
    "    mlflow.pytorch.log_model(model, \"model\")#, signature=signature)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = model(torch.tensor(input)[:1].to(DEVICE))[0][0].view(3, 64, 64).detach().cpu().numpy()\n",
    "# Y = x.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 64, 64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn(torch.tensor(Y), torch.tensor(X)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinforsment-learning-cw9s_yh0-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
